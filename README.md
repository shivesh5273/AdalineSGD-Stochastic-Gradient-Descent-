# Adaline Classifier with Stochastic Gradient Descent

This project demonstrates the Adaline (ADAptive LInear NEuron) algorithm trained with stochastic gradient descent (SGD), using Python and the Iris dataset.

## What is AdalineSGD?
AdalineSGD is a linear classifier that updates its weights after each training example, making it fast and suitable for large or streaming datasets.

## Stochastic Gradient Descent (SGD)
SGD is widely used in modern machine learning for efficient and scalable training, especially in deep learning.

## Project Structure
- `adaline_sgd.py`: Full Python code for AdalineSGD
- `README.md`: This file
- `results.pdf`: Notes and output graphs

## How to Run
1. Install requirements: `numpy`, `pandas`, `matplotlib`
2. Run the Python script in your IDE (e.g., PyCharm)
3. Review the generated cost and decision boundary plots

## Key Learnings
- How SGD speeds up convergence for large/online datasets
- Importance of feature scaling and data shuffling
- Real-world connection: SGD is the foundation of modern neural networks

## References
- Python Machine Learning by Sebastian Raschka
- [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/iris)

---

**See also:**  
Check my AdalineGD (Batch Gradient Descent) project for the batch learning version!
